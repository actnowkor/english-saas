# 백엔드 루프 개발 사양서 (지식파일용)

## 0) 범위(Scope) & 목표

* **목표:** “출제 → 제출 → 채점 → 라이트너 갱신 → 세션 종료/히스토리”의 **런타임 루프를 GUI 없이 안정화**한다.
* **비즈니스 전제:**

  * 문항 원본은 `items`에 존재하며, 출제 시점에 **스냅샷으로 동결**한다. 채점/복원은 **항상 스냅샷 기준**이다. 
  * **문장=개념 라이트너**, **단어/phrase=아이템 라이트너**로 구분한다.
  * `items.status`가 **draft/approved/archived**를 구분하며, **출제는 draft/approved 어디에서나 가능**(초기 테스트 목적). 은행 편입/운영은 `status` 전환으로 관리한다. 

---

## 1) 핵심 데이터 모델(요약)

### 1.1 필수 테이블(8)

* `users`: `id, display_name, preferred_level, goal_minutes_per_day, created_at` (개인 컨텍스트/집계)
* `items`: `id, type(sentence|phrase|word), level(A1|A2|B1), difficulty(1~5), concept_key, family_key, source_ko, answer_en, allowed_variants_text, near_misses_text, tags, status(draft|approved|archived), banked_at, reviewed_by, review_notes, parent_item_id, memo_json, created_at, updated_at` (출제 원본)
* `sessions`: `id, user_id, status(in_progress|abandoned|completed), target_item_count, started_at, ended_at, last_activity_at, restart_count, strategy_json, billing_note` (세트 단위 컨테이너)
* `session_items`: `id, session_id, item_id, order_index, snapshot_json, created_at` (출제 시점 스냅샷)
* `attempts`: `id, session_id, item_id, answer_raw, latency_ms, submitted_at` (사용자 제출)
* `grades`: `attempt_id, label(correct|variant|near_miss|wrong), error_tags, feedback_short, minimal_rewrite, role_view_text, judge(rule|ai), evidence_json, created_at` (채점/피드백)
* `user_item_status`: `user_id, item_id, box_level, last_attempt_at, next_due_at, interval_days, streak, total_attempts, correct_count, wrong_count, last_result, last_session_id, created_at` (단어/phrase 라이트너)
* `user_concept_status`: `user_id, concept_key, box_level, last_attempt_at, next_due_at, interval_days, streak, total_attempts, correct_count, wrong_count, last_result, last_session_id, preferred_difficulty, created_at` (문장 개념 라이트너)

### 1.2 선택 테이블

* `concepts`: `concept_key, display_name, description, level_range, recommended_difficulty_start, tags` (UI/검색 품질 보강)

### 1.3 문항 분류 체계(실무 키)

* **concept\_key 포맷:** `영역.시제/형태.문형/기능.세부` (예: `be.pres.svc.aff`) + **난이도 사다리(1→5)** 기반.
* **레벨 매핑:** A1(be/현재단순/There is/are + Wh(be)) → A2(과거/미래/SVOO + Wh(do/did)) → B1(진행/완료/수동/SVOC/복합/Wh 확장).
* **문장/phrase 타깃 유형:** 레벨별 핵심 패턴 및 자주 틀리는 포인트(관사·전치사·be 누락 등)를 **near\_misses**로 관리. 

---

# 2) 백엔드 루프 개발 사양서 — 변경 요약(리비전)

아래는 **사양서의 변경 포인트만** 요약입니다. (전체 문서는 기존 구조를 유지하되, 굵은 변경사항을 반영)

## 2.1 출제(세션 시작)

* **변경 전**: `start_session(p_user_id, p_count)` — 최신 아이템 기준 단순 출제.
* **변경 후**: `start_session_custom(p_user_id, p_type, p_count)` — **정책 테이블 기반 출제**

  * 정책 참조: `policy_level_mix`(레벨 배합), `policy_type_weights`(카테고리 비율), `policy_thresholds`(임계/기본값).
  * **inventory-aware 정규화**: 재고 없는 레벨/카테고리는 0% 처리 후 자동 재분배.
  * **세션 전략 기록**: `sessions.strategy_json`에 실제 사용된 비율·분배·언더필 플래그 기입.
  * **스냅샷**: 기존 필드 그대로 동결(채점 재현성 유지).

### 2.2 제출 수집(Attempt)

* **입력:** `session_id`, `item_id`, `answer_raw`, `latency_ms`
* **작업:** `attempts`에 저장(다중 시도 허용 가능).
* **출력:** `attempt_id`
* **사이드이펙트:** 채점 단계 트리거

### 2.3 채점(Grades) — **룰 우선 / AI 보조는 Stub**

* **입력:** `attempt_id`(→ 스냅샷·정답·variants 조회)
* **작업:**

  * 규칙 채점(정규화, 축약 허용, 관사 정책, phrase는 문장 금지 등) → `grades.label(correct|variant|near_miss|wrong)` 저장, `judge=rule`.
  * 오류 유형 태깅(`error_tags`: 관사 누락/전치사 오류/be 누락 등) 및 `feedback_short`, `minimal_rewrite` 기록.
  * 불확실 케이스는 `evidence_json`에 `needs_ai:true`로 표시(추후 AI 후처리 위해).
* **출력:** `grades` 1:1 레코드
* **사이드이펙트:** 라이트너 갱신 트리거

### 2.4 라이트너 갱신(SRS)

* **입력:** `grades.label`, `user_id`, (문장) `concept_key` / (phrase) `item_id`
* **작업:**

  * **단어/phrase:** `user_item_status` 업데이트(상/하향, `next_due_at`·`interval_days` 계산).
  * **문장(개념):** `user_concept_status` 업데이트 + `preferred_difficulty` 자동 상/하향(가드).
* **출력:** 갱신된 라이트너 상태
* **사이드이펙트:** 다음 출제 시 due 목록 반영

### 2.5 세션 완료 & 히스토리화

* **입력:** 세션 내 10문항 채점 완료 여부
* **작업:** `sessions.status=completed`, `ended_at` 저장. 요약(정답률, 평균 응답시간, near\_miss 분포) 계산·보관.
* **출력:** 세션 리절트(요약)
* **사이드이펙트:** 대시보드/히스토리 조회에서 사용

---

## 3) API 계약(Contract) — **엔드포인트 & 페이로드 스펙(코드 없음)**

> 실제 구현은 Next.js Route Handlers 또는 Edge Functions로 분할. 아래는 **요구 파라미터/반환 필드**의 계약만 정의.

1. * `POST /sessions`

  * **Body**: `{ user_id, type, count }`
  * **Return**: `{ session_id, items:[…], strategy:{type, level_mix, buckets, filled, target, underfilled} }`
  
2. `POST /attempts` — **제출 수집**

* **Body:** `{ session_id, item_id, answer_raw, latency_ms }`
* **Return:** `{ attempt_id }`

3. `POST /grades` — **채점(동기 룰-채점)**

* **Body:** `{ attempt_id }`
* **Return:** `{ label, error_tags, feedback_short, minimal_rewrite, judge, needs_ai }`

4. `POST /srs/update` — **라이트너 갱신**

* **Body:** `{ user_id, item_or_concept, label }`
* **Return:** `{ next_due_at, box_level, interval_days, streak }`

5. `POST /sessions/:id/complete` — **세션 완료**

* **Body:** `{ session_id }`
* **Return:** `{ summary: { correct_rate, avg_latency_ms, near_miss_breakdown }, ended_at }`

6. `GET /history` — **최근 세션/라이트너 현황**

* **Query:** `{ user_id, limit, from, to }`
* **Return:** `{ sessions:[{session_id, started_at, ended_at, stats}], srs:{items:[], concepts:[]} }`

> **주의:** 채점은 **항상 `session_items.snapshot_json` 기준**으로 수행한다(재현성).

---

## 4) 정책값(상수) → **정책 테이블로 이관**

* 기존 임시 상수(라이트너 간격표/가중치)는 점진 이관.
* **우선 이관 완료**: 타입 비율, 레벨 믹스, 세션 기본 문항수·임계. (정책 테이블은 이미 정의됨)
---

## 5) 콘텐츠 시드 가이드(최소 요건)

* **규모:** 총 30~~50개 `items` (A1/A2/B1 초반 골고루, 각 concept\_key 당 5~~10개, 사다리 1→3까지만)
* **필수 필드:** `type, level, difficulty, concept_key, family_key, source_ko, answer_en, allowed_variants_text, near_misses_text, status=draft`
* **레벨/타깃 유형 반영:** be/SVO/There is(존재) → 과거·미래·SVOO → 진행/완료/수동/SVOC(초반). phrase는 관사/전치사/be 누락 등 오류패턴 포함. 

---

## 6) AI 연동(지금은 Stub) — **호출 위치 & I/O 계약만**

* **문제 생성(선택):** *출제 전* “신규 아이템 제안” API 훅(비활성).

  * **Input:** `{ concept_key, level, difficulty, family_key(optional) }`
  * **Output(제안):** `{ source_ko, answer_en, variants, near_misses, tags }` (사람 검수 후 `items`로 편입)
* **채점 보조:** 룰 채점이 `needs_ai:true`일 때만 *비동기 후처리*로 AI 호출.

  * **Input:** `{ snapshot(answer_spec, variants, near_misses), answer_raw }`
  * **Output:** `{ ai_label, ai_feedback, evidence }` → `grades` 업데이트(`judge=ai`)
* **피드백 생성:** `feedback_short` 자동 개선(후순위).

> 현재 단계에서는 **실제 AI 호출은 OFF**. Stub 인터페이스만 확보하고 전 구간을 **룰 채점으로 통일**한다.

---

## 7) 품질/운영 가드라인

* **은행 편입:** `items.status`로 운영(초기엔 전부 `draft`로 출제 가능, 운영 전환 시 `approved`).
* **재현성:** 원본 `items` 변경과 무관하게 **스냅샷 기준 채점** 유지.
* **안전·금칙:** 민감 키워드/콘텐츠 제한은 정책표 상수로 시작.

---

## 8) 검증 체크리스트(무화면·Postman/CLI)

1. `POST /sessions`에 다양한 조합 테스트 
  * **10문제생성
  * **레벨 재고 부족/부재** 시에도 세션이 생성되는지(정규화·재분배 확인).
  * **레벨별 풀이<300**에서 `type=new_only` 강제가 적용되는지.
  * **underfilled**가 true일 때 UI 경고/표시가 노출되는지.

2. `POST /attempts` 여러 케이스 제출(정답/변형/근접/오답)
3. `POST /grades` → 라벨 분포 및 `judge=rule` 확인
4. `POST /srs/update`로 due/box\_level 변동 확인(재출제 시 due 우선 반영)
5. `POST /sessions/:id/complete` → 요약 통계 반환
6. `GET /history`로 최근 세션/라이트너 상태 조회

---

## 9) 인덱스 & 성능(초기)

* `sessions(user_id, status)`, `session_items(session_id, order_index)`,
  `attempts(session_id, item_id, submitted_at)`, `grades(attempt_id)`,
  `user_item_status(user_id, next_due_at)`, `user_concept_status(user_id, next_due_at)` — 조회/정렬 기준.

---

## 10) 용어/키 정리(개발자 가이드)

* **concept\_key:** 출제/복습의 “문장 개념” 식별자(예: `simple.pres.svo.aff`, `be.pres.q.yn`). 사다리 난이도 1→5로 설계.
* **family\_key:** 동일 주제/어휘군 묶음(사다리 버전 관리용).
* **near\_misses:** 흔한 오류(관사/전치사/be 누락/수일치 등)를 정규화해 정의. 채점/피드백에 활용.

---

## 한 줄 정리

* **핵심 변경은 오직 출제 단계**: `start_session_custom`이 **정책 테이블**을 읽어 **유연하게 출제**하고, **전략을 기록**합니다.
* 나머지(제출·채점·라이트너·완료·히스토리)는 기존 루프 그대로 사용하면 됩니다.


---

# 3) 프런트/서버 영향(짧게)

* **서버(API)**: `/api/sessions`에서 `p_type`·`p_count` 전달해 RPC 호출 방식만 변경(응답에 `strategy` 필드 추가 표시).&#x20;
* **대시보드**: 세션 타입 선택 모달에 4종 타입을 노출하고, 레벨별 풀이량<임계 시 `new_only` 안내/비활성.
* **학습 화면/이력**: 스냅샷 기반 로직은 동일(채점·라이트너 루프 불변).

